{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPridZUgE+qFV8HSW5Cdvfq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cartmarsh/DataAnalysis/blob/main/Toxic_comment_twitter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outline\n",
        "\n",
        "1. Get the tweets with tweepy\n",
        "2. load the model\n",
        "3. feed it the tweets\n",
        "\n",
        "4. Make some Data Analysis"
      ],
      "metadata": {
        "id": "6Mf2ITJdeq1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tweepy==4.1.0\n",
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy8gfPajejsG",
        "outputId": "60d551a2-c627-467c-9470-e3122c350f20"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tweepy==4.1.0\n",
            "  Downloading tweepy-4.1.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.1/62.1 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib<2,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tweepy==4.1.0) (1.3.1)\n",
            "Requirement already satisfied: requests<3,>=2.11.1 in /usr/local/lib/python3.8/dist-packages (from tweepy==4.1.0) (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.11.1->tweepy==4.1.0) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.11.1->tweepy==4.1.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.11.1->tweepy==4.1.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.11.1->tweepy==4.1.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib<2,>=1.0.0->tweepy==4.1.0) (3.2.2)\n",
            "Installing collected packages: tweepy\n",
            "  Attempting uninstall: tweepy\n",
            "    Found existing installation: tweepy 3.10.0\n",
            "    Uninstalling tweepy-3.10.0:\n",
            "      Successfully uninstalled tweepy-3.10.0\n",
            "Successfully installed tweepy-4.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-0.21.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-0.21.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQmQA3alfA-G",
        "outputId": "04460b97-3198-4a99-a4f8-19857e2615ab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.8/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.8/dist-packages (from textblob) (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (2022.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordcloud\n",
        "!pip install better_profanity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQs42f7PfDSG",
        "outputId": "378e889e-3420-4038-af56-ecf0df0ac7db"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.8/dist-packages (1.8.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from wordcloud) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.8/dist-packages (from wordcloud) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from wordcloud) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->wordcloud) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting better_profanity\n",
            "  Downloading better_profanity-0.7.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.1/46.1 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: better_profanity\n",
            "Successfully installed better_profanity-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re \n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tweepy \n",
        "\n",
        "from tweepy import OAuthHandler \n",
        "\n",
        "from textblob import TextBlob \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "from better_profanity import profanity"
      ],
      "metadata": {
        "id": "B6GuDHpOfF2e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "consumer_key = 'uS3mcCvexB7CLcalnKTcEgzqo'\n",
        "consumer_secret = 'ensBvZme0LUyTEqYq8XTxtjrNPyzms5slM1GaxmS6k7yxzzEy2' \n",
        "access_token = '840693273345822720-9lil2py7RXN0gkuvOyOOCcnFjAUJ7CU'\n",
        "access_token_secret = '4wOCEbHoLW8cXFJWXw4QYvUp4t5MvNQTvBC2UbFUZ9hQq'"
      ],
      "metadata": {
        "id": "QNcGdsVEfFzs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "\n",
        "api = tweepy.API(auth)"
      ],
      "metadata": {
        "id": "3kiDPuzffEu9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweepy.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iYMV9-I7fgaL",
        "outputId": "6c31099c-f01f-467e-e907-e067aeafcf97"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.1.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input a query from the user\n",
        "\n",
        "query = input(\"Please enter your topic / person of interest: \")\n",
        "\n",
        "# In this case, we will input the query as 'Elon Musk'\n",
        "\n",
        "# Filter the query to remove retweets\n",
        "\n",
        "filtered = query + \"-filter:retweets\"\n",
        "\n",
        "# Generate the latest tweets on the given query \n",
        "\n",
        "tweets = tweepy.Cursor(api.search_tweets, \n",
        "                           q=filtered,\n",
        "                           lang=\"en\").items(100)\n",
        "\n",
        "# Create a list of the tweets, the users, and their location\n",
        "\n",
        "list1 = [[tweet.text, tweet.user.screen_name, tweet.user.location] for tweet in tweets]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fLkYUSKfEr_",
        "outputId": "98007559-501c-4e77-dde5-04c178c861c0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your topic / person of interest: Pyramids\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the list into a dataframe\n",
        "\n",
        "df = pd.DataFrame(data=list1, \n",
        "                    columns=['tweets','user', \"location\"])\n",
        "# Convert only the tweets into a list\n",
        "\n",
        "tweet_list = df.tweets.to_list()"
      ],
      "metadata": {
        "id": "eogy1FCmfEo_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_list[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fPJTFadfElv",
        "outputId": "8fcfa324-f38c-465f-9a42-90a987c6c33c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@minnySODAguy Humans did not solely build the pyramids.. idk who did or helped but I can‚Äôt fathom humans at the tim‚Ä¶ https://t.co/pEjia2DxmQ',\n",
              " '@fasc1nate Personally I accept levitation as the method of assembling the giant stones, they knew what caused gravi‚Ä¶ https://t.co/ywaX0FuIlk',\n",
              " '\"The ancient Egyptian pyramids have stood for thousands of years and are among the world\\'s most enduring monuments.‚Ä¶ https://t.co/G6QgcwQt4T',\n",
              " 'üî¥ LIVE PODCAST: Nibiru? Episode 213 - Dark Skies News And information on @Spreaker #darkskiespodcast #egypt‚Ä¶ https://t.co/hLSMS9SH8G',\n",
              " 'Step Pyramid in Saqqara.\\nAnother great site you will experience with us!\\nCome travel with us!\\n\\n#travel\\n#ancient‚Ä¶ https://t.co/7MqJyrvxcg',\n",
              " 'We are thrilled that on Wednesday, February 22nd we will have The Pyramids Food Truck here from 5pm - 7:30pm!! We h‚Ä¶ https://t.co/q9chyayL22',\n",
              " 'New Audiobook Addition to Easy Nevada and the Pyramid‚Äôs Curse by Georgette Kaplan: Audiobook Review‚Ä¶ https://t.co/rnQ1JIpXXO',\n",
              " 'In case you missed it\\n\\n Michelle: Easy Nevada and the Pyramid‚Äôs Curse by Georgette Kaplan is an adrenaline-fueled a‚Ä¶ https://t.co/Se9g0q6HcN',\n",
              " 'https://t.co/cyKogq2Tbu How did the majestic pyramids of Ancient Egypt appear in their original form?‚Ä¶ https://t.co/1CN6FqWQ6E',\n",
              " 'üá™üá¨\\nJosefina en las Pyramids‚Ä¶\\n.\\n.\\n.\\n#Giza #ElCairo #Egypt #Keops #Kefren #Micerinos #Travel #Trips #Viajeros‚Ä¶ https://t.co/SNaYFnXIkf']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can improve the stopwords here by donwloading a library"
      ],
      "metadata": {
        "id": "mhRD7-ltg7mN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_tweet(tweet):\n",
        "    if type(tweet) == float:\n",
        "        return \"\"\n",
        "    r = tweet.lower()\n",
        "    r = profanity.censor(r)\n",
        "    r = re.sub(\"'\", \"\", r) # This is to avoid removing contractions in english\n",
        "    r = re.sub(\"@[A-Za-z0-9_]+\",\"\", r)\n",
        "    r = re.sub(\"#[A-Za-z0-9_]+\",\"\", r)\n",
        "    r = re.sub(r'http\\S+', '', r)\n",
        "    r = re.sub('[()!?]', ' ', r)\n",
        "    r = re.sub('\\[.*?\\]',' ', r)\n",
        "    r = re.sub(\"[^a-z0-9]\",\" \", r)\n",
        "    r = r.split()\n",
        "    stopwords = [\"for\", \"on\", \"an\", \"a\", \"of\", \"and\", \"in\", \"the\", \"to\", \"from\"]\n",
        "    r = [w for w in r if not w in stopwords]\n",
        "    r = \" \".join(word for word in r)\n",
        "    return r"
      ],
      "metadata": {
        "id": "H79XCPlGfEin"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned = [clean_tweet(tw) for tw in tweet_list]\n",
        "cleaned[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNJQmGbMfEcQ",
        "outputId": "599b47da-a3de-44da-a397-7414c6b19978"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['humans did not solely build pyramids idk who did or helped but i can t fathom humans at tim',\n",
              " 'personally i accept levitation as method assembling giant stones they knew what caused gravi',\n",
              " 'ancient egyptian pyramids have stood thousands years are among worlds most enduring monuments',\n",
              " 'live podcast nibiru episode 213 dark skies news information',\n",
              " 'step pyramid saqqara another great site you will experience with us come travel with us',\n",
              " 'we are thrilled that wednesday february 22nd we will have pyramids food truck here 5pm 7 30pm we h',\n",
              " 'new audiobook addition easy nevada pyramid s curse by georgette kaplan audiobook review',\n",
              " 'case you missed it michelle easy nevada pyramid s curse by georgette kaplan is adrenaline fueled',\n",
              " 'how did majestic pyramids ancient egypt appear their original form',\n",
              " 'josefina en las pyramids']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using"
      ],
      "metadata": {
        "id": "zBshDbP8MBnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Huggingface sentiment model\n",
        "\n",
        "Using huggingface sentiment analysis model"
      ],
      "metadata": {
        "id": "4NXAoydVMDpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMP5RnJrOhKG",
        "outputId": "c6df570a-2579-4a5a-bbf6-6393e0110350"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer, AutoConfig\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "# Preprocess text (username and link placeholders)\n",
        "def preprocess(text):\n",
        "    new_text = []\n",
        "    for t in text.split(\" \"):\n",
        "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
        "        t = 'http' if t.startswith('http') else t\n",
        "        new_text.append(t)\n",
        "    return \" \".join(new_text)\n",
        "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "config = AutoConfig.from_pretrained(MODEL)\n",
        "# PT\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "model.save_pretrained(MODEL)\n",
        "\n",
        "for tweet in cleaned:\n",
        "  text = tweet\n",
        "  text = preprocess(text)\n",
        "  encoded_input = tokenizer(text, return_tensors='pt')\n",
        "  output = model(**encoded_input)\n",
        "  scores = output[0][0].detach().numpy()\n",
        "  scores = softmax(scores)\n",
        "  # # TF\n",
        "  # model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "  # model.save_pretrained(MODEL)\n",
        "  # text = \"Covid cases are increasing fast!\"\n",
        "  # encoded_input = tokenizer(text, return_tensors='tf')\n",
        "  # output = model(encoded_input)\n",
        "  # scores = output[0][0].numpy()\n",
        "  # scores = softmax(scores)\n",
        "  # Print labels and scores\n",
        "  ranking = np.argsort(scores)\n",
        "  ranking = ranking[::-1]\n",
        "  print(tweet)\n",
        "  for i in range(scores.shape[0]):\n",
        "      l = config.id2label[ranking[i]]\n",
        "      s = scores[ranking[i]]\n",
        "      print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb-_-HCKMNM7",
        "outputId": "2fab6258-e685-4b9b-9659-c1f4579fa7d4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "humans did not solely build pyramids idk who did or helped but i can t fathom humans at tim\n",
            "1) negative 0.8221\n",
            "2) neutral 0.1663\n",
            "3) positive 0.0116\n",
            "personally i accept levitation as method assembling giant stones they knew what caused gravi\n",
            "1) neutral 0.6944\n",
            "2) negative 0.2077\n",
            "3) positive 0.0979\n",
            "ancient egyptian pyramids have stood thousands years are among worlds most enduring monuments\n",
            "1) neutral 0.5323\n",
            "2) positive 0.4502\n",
            "3) negative 0.0175\n",
            "live podcast nibiru episode 213 dark skies news information\n",
            "1) neutral 0.9419\n",
            "2) positive 0.0482\n",
            "3) negative 0.01\n",
            "step pyramid saqqara another great site you will experience with us come travel with us\n",
            "1) positive 0.9774\n",
            "2) neutral 0.0207\n",
            "3) negative 0.0019\n",
            "we are thrilled that wednesday february 22nd we will have pyramids food truck here 5pm 7 30pm we h\n",
            "1) positive 0.9892\n",
            "2) neutral 0.0096\n",
            "3) negative 0.0012\n",
            "new audiobook addition easy nevada pyramid s curse by georgette kaplan audiobook review\n",
            "1) neutral 0.7628\n",
            "2) positive 0.2137\n",
            "3) negative 0.0235\n",
            "case you missed it michelle easy nevada pyramid s curse by georgette kaplan is adrenaline fueled\n",
            "1) neutral 0.7977\n",
            "2) positive 0.1477\n",
            "3) negative 0.0546\n",
            "how did majestic pyramids ancient egypt appear their original form\n",
            "1) neutral 0.8304\n",
            "2) positive 0.1115\n",
            "3) negative 0.0581\n",
            "josefina en las pyramids\n",
            "1) neutral 0.859\n",
            "2) positive 0.0941\n",
            "3) negative 0.0469\n",
            "as pyramids testify egyptians so my glorious shall represent our culture perpetuity behold ri\n",
            "1) neutral 0.6608\n",
            "2) positive 0.3194\n",
            "3) negative 0.0198\n",
            "does anyone know how population pyramids can reflect individuals who do not identify their gender as male or female\n",
            "1) neutral 0.7943\n",
            "2) negative 0.1935\n",
            "3) positive 0.0122\n",
            "great pyramids at giza pigeon keepers trash collectors metalworker crowded markets ancient alleyways\n",
            "1) positive 0.5818\n",
            "2) neutral 0.3877\n",
            "3) negative 0.0305\n",
            "all nation states are capitalist they\n",
            "1) negative 0.6226\n",
            "2) neutral 0.3485\n",
            "3) positive 0.029\n",
            "what if we could enter wormhole travel distance required look back at earth with macros\n",
            "1) neutral 0.8677\n",
            "2) positive 0.0918\n",
            "3) negative 0.0406\n",
            "pyramids have existed throughout planet even before atlantis pyramids are powerful anchor points cosm\n",
            "1) neutral 0.6095\n",
            "2) positive 0.3637\n",
            "3) negative 0.0269\n",
            "1812 albert einstein slept pyramids with george orwell while they picked their nose\n",
            "1) neutral 0.8889\n",
            "2) positive 0.0663\n",
            "3) negative 0.0448\n",
            "theres more than pyramids sand egypt todays tomb raider anniversary episode youll see most dia\n",
            "1) neutral 0.7586\n",
            "2) positive 0.1903\n",
            "3) negative 0.0511\n",
            "ever wondered what secrets lie inside pyramids giza check out this short some crazy facts\n",
            "1) neutral 0.7787\n",
            "2) negative 0.1148\n",
            "3) positive 0.1064\n",
            "which one there are 3 major pyramids yhe giza planes 50 or 60 smaller pyramids so which one\n",
            "1) neutral 0.8486\n",
            "2) positive 0.0941\n",
            "3) negative 0.0573\n",
            "there is hidden powers great pyramid giza pyramids contain cosmic energies these energies comes our\n",
            "1) neutral 0.6241\n",
            "2) positive 0.3494\n",
            "3) negative 0.0265\n",
            "give us another year we will give you something that rivals european leagues\n",
            "1) positive 0.4785\n",
            "2) neutral 0.4646\n",
            "3) negative 0.0569\n",
            "id youd like see other pieces my work you can go search pyramids giza\n",
            "1) neutral 0.6772\n",
            "2) positive 0.3028\n",
            "3) negative 0.02\n",
            "m7 think egyptian pyramids how were they built\n",
            "1) neutral 0.878\n",
            "2) negative 0.0819\n",
            "3) positive 0.0401\n",
            "slaves didnt build america get off that bs if slaves built america why isnt africa firs\n",
            "1) negative 0.8373\n",
            "2) neutral 0.1542\n",
            "3) positive 0.0085\n",
            "seigfried pyramids i with most\n",
            "1) neutral 0.7328\n",
            "2) positive 0.1678\n",
            "3) negative 0.0995\n",
            "they already did it you all first life set so line up bc it s shifted pyramids have been replicated i\n",
            "1) neutral 0.882\n",
            "2) positive 0.0679\n",
            "3) negative 0.0501\n",
            "uh actually pyramids are pyramids not tetrahedrons\n",
            "1) neutral 0.7934\n",
            "2) positive 0.1125\n",
            "3) negative 0.0941\n",
            "pyramids were not built overnight\n",
            "1) neutral 0.7674\n",
            "2) positive 0.1191\n",
            "3) negative 0.1135\n",
            "so they say us humans couldnt have built pyramids with todays technology but we are capable making this\n",
            "1) neutral 0.6197\n",
            "2) negative 0.1962\n",
            "3) positive 0.1841\n",
            "but cleopatra was born 2000 years after pyramids were built what we\n",
            "1) neutral 0.7419\n",
            "2) negative 0.2224\n",
            "3) positive 0.0357\n",
            "maybe they can replace anti tank pyramids\n",
            "1) neutral 0.7594\n",
            "2) negative 0.1609\n",
            "3) positive 0.0797\n",
            "artificial portal where if pyramids were generating energy w\n",
            "1) neutral 0.8834\n",
            "2) positive 0.0663\n",
            "3) negative 0.0504\n",
            "alien intervention raelians pyramids nazca geoglyphs bills bible basics article this article can be r\n",
            "1) neutral 0.8427\n",
            "2) positive 0.0933\n",
            "3) negative 0.064\n",
            "things i d do hear this concert\n",
            "1) positive 0.5535\n",
            "2) neutral 0.344\n",
            "3) negative 0.1025\n",
            "fact pyramids are really low tec they are just lot work therefore sign wealth power\n",
            "1) negative 0.4925\n",
            "2) neutral 0.461\n",
            "3) positive 0.0465\n",
            "who built pyramids takes bible\n",
            "1) neutral 0.6572\n",
            "2) negative 0.2771\n",
            "3) positive 0.0656\n",
            "does whole mars catalog have merch like yurts bongs rolling papers black lights tie dyed sh\n",
            "1) neutral 0.9074\n",
            "2) positive 0.049\n",
            "3) negative 0.0436\n",
            "egypt vlog giza great pyramids 2023 via egypt vlog out now\n",
            "1) positive 0.5589\n",
            "2) neutral 0.4359\n",
            "3) negative 0.0051\n",
            "did you know pyramids make peace with clocks\n",
            "1) neutral 0.8644\n",
            "2) positive 0.1156\n",
            "3) negative 0.02\n",
            "i have they all over world too bible only 6 000 yrs old tops those obelisks you mentioned\n",
            "1) neutral 0.7402\n",
            "2) positive 0.1841\n",
            "3) negative 0.0757\n",
            "tangent pyramids stars other sories triple live vinyl dream realised andy tillison\n",
            "1) neutral 0.8779\n",
            "2) positive 0.1065\n",
            "3) negative 0.0156\n",
            "pyramids\n",
            "1) neutral 0.6744\n",
            "2) positive 0.2178\n",
            "3) negative 0.1078\n",
            "i was taught that egyptians did not know about wheel pyramids are tombs this one deep under\n",
            "1) neutral 0.6375\n",
            "2) negative 0.3376\n",
            "3) positive 0.0248\n",
            "ha ha older than pyramids too funny\n",
            "1) positive 0.4951\n",
            "2) neutral 0.4065\n",
            "3) negative 0.0984\n",
            "i ve just done this recently more straightforward parts pop environ dtm pop py\n",
            "1) neutral 0.8256\n",
            "2) positive 0.1626\n",
            "3) negative 0.0117\n",
            "they built lots smaller pyramids beforehand praise imhotep\n",
            "1) neutral 0.5881\n",
            "2) positive 0.3476\n",
            "3) negative 0.0643\n",
            "gong dollar sign by pyramids production is\n",
            "1) neutral 0.7857\n",
            "2) positive 0.1279\n",
            "3) negative 0.0863\n",
            "unholy androgine freedom tower anti prism black\n",
            "1) negative 0.5045\n",
            "2) neutral 0.4742\n",
            "3) positive 0.0214\n",
            "my people direct descendants atlanteans been building pyramids since start\n",
            "1) neutral 0.6612\n",
            "2) negative 0.2716\n",
            "3) positive 0.0671\n",
            "illuminating pyramids stars\n",
            "1) neutral 0.7948\n",
            "2) positive 0.1712\n",
            "3) negative 0.034\n",
            "some educators straight out tell you dont want personal experiences instead app\n",
            "1) negative 0.7647\n",
            "2) neutral 0.2249\n",
            "3) positive 0.0104\n",
            "i need short version pyramids by frank ocean bc its such good song but it is soooooo long\n",
            "1) positive 0.3491\n",
            "2) negative 0.3364\n",
            "3) neutral 0.3144\n",
            "triangles are powerful more specifically i like pyramids think maslowes hierarchy visually they tell few s\n",
            "1) positive 0.8244\n",
            "2) neutral 0.161\n",
            "3) negative 0.0147\n",
            "entire discourse around hogwarts legacy is going set trans rights back time before pyramids were built isnt it\n",
            "1) neutral 0.6324\n",
            "2) negative 0.3283\n",
            "3) positive 0.0393\n",
            "just told my bf there are pyramids tallaght that square shopping centre was built commemorate them he was convinced\n",
            "1) neutral 0.5805\n",
            "2) positive 0.3711\n",
            "3) negative 0.0484\n",
            "pyramids giza stepped pyramids are djosers that s amazing though happy you fr\n",
            "1) positive 0.9749\n",
            "2) neutral 0.0215\n",
            "3) negative 0.0036\n",
            "we don t watch videos his imagination we watch him because his videos are based\n",
            "1) neutral 0.7503\n",
            "2) negative 0.1843\n",
            "3) positive 0.0654\n",
            "we used build pyramids\n",
            "1) neutral 0.8277\n",
            "2) positive 0.0985\n",
            "3) negative 0.0737\n",
            "people that built pyramids had power tools dont me\n",
            "1) neutral 0.5456\n",
            "2) negative 0.3981\n",
            "3) positive 0.0563\n",
            "jre pyramids giza\n",
            "1) neutral 0.8131\n",
            "2) positive 0.0951\n",
            "3) negative 0.0918\n",
            "ancient sands have whispered tales pharaohs pyramids millennia this egypt 4 day\n",
            "1) neutral 0.8126\n",
            "2) negative 0.1502\n",
            "3) positive 0.0372\n",
            "get my art printed awesome products at redbubble\n",
            "1) positive 0.9396\n",
            "2) neutral 0.0582\n",
            "3) negative 0.0022\n",
            "slaves built pyramids too so let s knock em down ground\n",
            "1) neutral 0.5202\n",
            "2) negative 0.4493\n",
            "3) positive 0.0305\n",
            "this is reason why no one knows how them old pyramids monuments were built cuz generation woul\n",
            "1) negative 0.6195\n",
            "2) neutral 0.3662\n",
            "3) positive 0.0143\n",
            "pyramids are not impressive\n",
            "1) negative 0.8051\n",
            "2) neutral 0.1601\n",
            "3) positive 0.0348\n",
            "later builders refined design pyramids we so well know today all this happened 4 700 years ago durin\n",
            "1) neutral 0.8016\n",
            "2) positive 0.1108\n",
            "3) negative 0.0876\n",
            "telling time fashioning stretchers asking me who left all pyramids\n",
            "1) neutral 0.8506\n",
            "2) negative 0.0832\n",
            "3) positive 0.0662\n",
            "dude pyramids i m literally building power generating pyramids need help time do it is t\n",
            "1) negative 0.549\n",
            "2) neutral 0.3589\n",
            "3) positive 0.0921\n",
            "victimhood jewish ppl have been claim\n",
            "1) neutral 0.595\n",
            "2) negative 0.3791\n",
            "3) positive 0.0259\n",
            "just take look at pyramids hugh effort just 1 burial\n",
            "1) neutral 0.666\n",
            "2) negative 0.2644\n",
            "3) positive 0.0696\n",
            "not really youre talking about pyramids which havent been mentioned anywhere\n",
            "1) neutral 0.6365\n",
            "2) negative 0.3296\n",
            "3) positive 0.0339\n",
            "show him diagram egyptian pyramids inards\n",
            "1) neutral 0.8046\n",
            "2) negative 0.0992\n",
            "3) positive 0.0963\n",
            "egyptian traditions has been found all over africa non middle east or europe even sudan having t\n",
            "1) neutral 0.8633\n",
            "2) positive 0.0938\n",
            "3) negative 0.0429\n",
            "fun fact back day pyramids were white imagine how those would have looked ancients\n",
            "1) neutral 0.7241\n",
            "2) positive 0.1627\n",
            "3) negative 0.1131\n",
            "not pyramids babe xd\n",
            "1) neutral 0.5547\n",
            "2) negative 0.3891\n",
            "3) positive 0.0562\n",
            "joe rogan do we really know how old pyramids are via\n",
            "1) neutral 0.8536\n",
            "2) negative 0.1266\n",
            "3) positive 0.0197\n",
            "why don t we just build things with giant legos everything would be constructed so much faster it worked\n",
            "1) positive 0.4686\n",
            "2) neutral 0.3992\n",
            "3) negative 0.1322\n",
            "i once gave 30 minute lecture evolution egyptian pyramids all my friend said is she liked\n",
            "1) positive 0.6728\n",
            "2) neutral 0.3115\n",
            "3) negative 0.0156\n",
            "\n",
            "1) positive 0.4013\n",
            "2) neutral 0.3731\n",
            "3) negative 0.2256\n",
            "venn diagram these people aliens made pyramids has be circle right i am over\n",
            "1) negative 0.6882\n",
            "2) neutral 0.2801\n",
            "3) positive 0.0317\n",
            "why do food pyramids i really like this one always skip most important food clean wat\n",
            "1) negative 0.5885\n",
            "2) neutral 0.2786\n",
            "3) positive 0.1329\n",
            "ancient egypt i thought 100 tax slaves who apparently built pyramids ever\n",
            "1) neutral 0.659\n",
            "2) negative 0.2999\n",
            "3) positive 0.041\n",
            "someone is blasting pyramids by frank ocean at jol yoh\n",
            "1) neutral 0.7632\n",
            "2) negative 0.1374\n",
            "3) positive 0.0994\n",
            "amp are about announce that they will be turning great pyramids egypt back\n",
            "1) positive 0.8078\n",
            "2) neutral 0.1875\n",
            "3) negative 0.0047\n",
            "gm been off platform awhile 4 images are recent work 2023\n",
            "1) neutral 0.564\n",
            "2) negative 0.4121\n",
            "3) positive 0.0239\n",
            "resource question pyramid high challenge low threat quizzing disguise this i\n",
            "1) neutral 0.8617\n",
            "2) negative 0.0972\n",
            "3) positive 0.0412\n",
            "blacks have history oh yeah pyramids egypt right\n",
            "1) neutral 0.8382\n",
            "2) positive 0.0891\n",
            "3) negative 0.0727\n",
            "i hate it when baby boomers pyramids this enrages me\n",
            "1) negative 0.9396\n",
            "2) neutral 0.052\n",
            "3) positive 0.0084\n",
            "enderman built pyramids think about it\n",
            "1) neutral 0.7498\n",
            "2) negative 0.1717\n",
            "3) positive 0.0785\n",
            "bra pyramids giza are twice older than existence jesus christ both himself as religion they\n",
            "1) neutral 0.8049\n",
            "2) positive 0.1262\n",
            "3) negative 0.0689\n",
            "egyptians have earliest known glass earliest known lenses\n",
            "1) neutral 0.8707\n",
            "2) positive 0.1125\n",
            "3) negative 0.0168\n",
            "pyramids 5 continents around world\n",
            "1) neutral 0.7267\n",
            "2) positive 0.2432\n",
            "3) negative 0.0301\n",
            "pyramids giza\n",
            "1) neutral 0.7222\n",
            "2) positive 0.2445\n",
            "3) negative 0.0333\n",
            "every technology we have today our govt stole tesla nick years ago pyramids are not egyptian either\n",
            "1) negative 0.7963\n",
            "2) neutral 0.1912\n",
            "3) positive 0.0125\n",
            "uh can i interest you with classic who series 13 with terror zygons pyrami\n",
            "1) neutral 0.8712\n",
            "2) positive 0.1119\n",
            "3) negative 0.017\n",
            "sudan has most pyramids world not egypt region sudan called nubia has 255 pyramids twice numb\n",
            "1) neutral 0.5748\n",
            "2) negative 0.3838\n",
            "3) positive 0.0415\n",
            "absolutely i got version this whenever i told ppl i did ethnographic research\n",
            "1) neutral 0.6788\n",
            "2) negative 0.1921\n",
            "3) positive 0.1291\n",
            "check out hieroglyphs central coast nsw gympi pyramids gympi ape\n",
            "1) neutral 0.8905\n",
            "2) positive 0.0906\n",
            "3) negative 0.0189\n",
            "they would need cut move place 5 blocks minute build it how they claim thes\n",
            "1) neutral 0.7226\n",
            "2) negative 0.2429\n",
            "3) positive 0.0345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ag3NCNpsMOVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s5myMekIMOSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ehJ4vhtGMOQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w_p2Jk5XMOOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Lwbt2h1MOKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bfmOvaUZMOGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kOkYFKzpMODE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pjQnSCz2MN9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sTtgzG5NMN5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jmZkg3LrMN3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "COMr8mlBMNwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gxt6iztGMNo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the model"
      ],
      "metadata": {
        "id": "hm4cPSwkhTXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "qcJ8L4P2fEPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n"
      ],
      "metadata": {
        "id": "Yu1G8M1ihqlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "ahby2noGhtNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(\"./checkpointRNN_toxic_comment_classifier.ckpt\")"
      ],
      "metadata": {
        "id": "mVM2_fkOfEM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning"
      ],
      "metadata": {
        "id": "l4N6IBrkimMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl"
      ],
      "metadata": {
        "id": "ljCIHoU2h4ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the data for prediction"
      ],
      "metadata": {
        "id": "gxI9a0bSi_MK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer"
      ],
      "metadata": {
        "id": "u2tGn00dijhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")"
      ],
      "metadata": {
        "id": "gkToM50XjCGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator"
      ],
      "metadata": {
        "id": "KyB7CyyTjE45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comments_token = [tokenizer(comment) for comment in cleaned]"
      ],
      "metadata": {
        "id": "M4eKUxjOjOWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comments_token = pd.DataFrame(comments_token)"
      ],
      "metadata": {
        "id": "cPwIHPUvp25q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comments_token[:10]"
      ],
      "metadata": {
        "id": "gJDucucHjdMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 1500"
      ],
      "metadata": {
        "id": "NougEAWhjpcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## for words that are unknown to the vocab\n",
        "unk_token = \"\"\n",
        "\n",
        "## to pad sentences, because we need the same length for RNNs\n",
        "pad_token = \"\""
      ],
      "metadata": {
        "id": "896iVKPmjyw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = build_vocab_from_iterator(comments_token, specials=[unk_token, pad_token],\n",
        "                                  max_tokens=VOCAB_SIZE)"
      ],
      "metadata": {
        "id": "SLRWC1p4j0FD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "RRnsBXOwj0CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class JigsawDataset(Dataset):\n",
        "  def __init__(self, df, is_test=False):\n",
        "    self.df = df\n",
        "    self.is_test = is_test\n",
        "    \n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    comment_text = self.df.comment_text.values[index]\n",
        "    comment_tokens = pad_tokens(tokenizer(comment_text))\n",
        "    input = torch.tensor(vocab.lookup_indices(comment_tokens))\n",
        "    if self.is_test:\n",
        "      target = torch.tensor([0,0,0,0,0,0]).float()\n",
        "    else:\n",
        "      target = torch.tensor(self.df[target_cols].values[index]).float()\n",
        "    return input, target\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)"
      ],
      "metadata": {
        "id": "NaCpDcOKjz_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OQpupO6kjz8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XAXYNgqUjz6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LUCt7JROjz3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "caB9ExNpjz0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "52sqaC1djzxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2s1dqtTNjzus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bKrSr_kujzrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LIo3yl1Xjzo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nFNlm99XjzmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "obaLHsHQjzi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jx-i8Lrojzf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hWc4jbcvjza-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Z9mqRUfjzUW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}